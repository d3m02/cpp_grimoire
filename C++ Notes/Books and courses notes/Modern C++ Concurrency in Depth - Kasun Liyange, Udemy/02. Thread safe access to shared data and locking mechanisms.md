**Invariants** — statements regarding program state that are always true. This applies to class logic, algorithms, and data structures. For example, in the doubly linked list data structure, if we follow a `next` pointer from node A to node B, the `prev` pointer in B should point to node A.

The most common problem in multithreaded applications is broken invariants during updates. One particular example is deleting a node from a doubly linked list. In the doubly linked list data structure, if we follow a `next` pointer from node A to node B, the `prev` pointer in B should point to node A — this is an invariant for a doubly linked list. Deleting one node requires two steps:
1. Change node A's `next` pointer to node C (instead of B).
2. Change node C's `prev` pointer to node A (instead of B).

But let's say that after executing step 1, another thread tries to read the list in reverse order. In this case, node B's `prev` pointer points to node A, but node A's `next` pointer is already pointing to node C. This situation represents a broken invariant. In this scenario, if another thread starts removing another node, the data structure as a whole becomes invalid.

**Race condition** — in concurrency, a race condition is anything where the outcome depends on the relative ordering of the execution of operations on two or more threads. In most cases, the order of execution doesn't affect the result, but for problematic race conditions (specifically _data races_ in C++), we need additional management to receive valid output.

## Mutex 
The `std::mutex` is a synchronization primitive that can be used to protect shared data from being simultaneously accessed by multiple threads. We can simply say that mutex provides mutual exclusive access of shared data for multiple threads. 

Let's take as an example scenario of adding new element to `std::list`. `std::list` is not built as thread-safe data structure. STL containers generally offer basic thread safety (safe for concurrent reads), but they are _not thread-safe for concurrent writes_. Pushing an element to list is not atomic operation and it in general contain 3 steps: creating new node, setting `next` pointer of that node to current head node and changing in head node `prev` pointer to the new node. If two threads start adding new element, only one node will be accessible from old head node, meaning that another node will be lost. Thus, when we already have some mutable operation, we need to prevent another node from starting same operation until first operation not finished. 

`std::mutex` have only three member functions: 
+ `{cpp} void lock()` - locks mutex, if another thread has already locked the mutex, a call to `lock` will block execution until the lock is acquired.
+ `{cpp}void unlock()` - unlocks the mutex. The mutex must be locked by the current thread of execution.
+ `{cpp} bool try_lock()` - tries to lock the mutex and returns immediately `true` if mutex get locked.

When a thread calls `lock()` on an already locked mutex, the operating system puts the thread to sleep (removes it from the CPU scheduling queue). The thread consumes no processor time until the mutex is unlocked and the OS wakes the thread up.

For `std::list` example, inside callable object we firstly lock the mutex. When another thread tries to lock the mutex, it will be blocked until the first thread releases the mutex. After the first thread unlocks the mutex, the execution of the second thread will be resumed by the OS, and now the second thread acquires the lock.
```cpp
std::list<int> list;
std::mutex m;

void addToList(const int x) {
	m.lock();
	list.push_front(x);
	m.unlock();
}

void func() {
	std::jthread t1 {addToList, 4};
	std::jthread t2 {addToList, 11};
}
```

As we can notice from example, unlocking mutex is crucial part. If the first thread does not unlock the mutex (e.g., due to an exception), two critical problems arise:
1. _Starvation:_ Other threads waiting for this mutex will be blocked forever.
2. _Undefined Behavior (Self-Deadlock):_ If the thread that holds the lock attempts to catch the exception and lock the mutex again, it triggers Undefined Behavior (since `std::mutex` is non-recursive), typically resulting in a self-deadlock.

To avoid such situations, we should use an RAII wrapper. The STL provides the class `std::lock_guard(mutex_type& m);` — a mutex wrapper that provides a convenient RAII-style mechanism for owning a mutex for the duration of a scoped block. When a `std::lock_guard` object is created, it attempts to take ownership of the mutex it's given. After leaving the scope, the `std::lock_guard` object is destroyed, unlocking the mutex in the destructor.
Starting from C++17 STL also provides `{cpp}std::scoped_lock(MutexTypes&... m);` - similar to `std::lock_guard` RAII wrapper, but with ability to lock multiple mutexes using a deadlock avoidance algorithm

```cpp
std::list<int> list;
std::mutex m;

void addToList(const int x) {
	std::lock_guard<std::mutex> lg(m);
	list.push_front(x);
}

void func() {
	std::jthread t1 {addToList, 4};
	std::jthread t2 {addToList, 11};
}
```

## Thread safe stack implementation. 
> Section more based on book C++ Concurrency in Action, 2nd Edition by A Williams, since looks like author on this course most of example took from that book
STL provides an implementation of a LIFO (last-in, first-out) data structure - `std::stack`. It's not a container, it's a container adapter, which can be based on top of `std::deque`. As we mentioned, STL containers doesn't provide thread safety for writing operation.

We can solve this issue by creating own `stack` implementation  using `std::stack` as underlying container. Container adapters usually simply call member function of underlying container. We going to protect those calls to underlying container with `std::mutex` and `std::lock_guard` to prevent situations, when two thread trying to simultaneously modify container or one thread adding removing one element while another checking is container not empty. 
```cpp
template<typename T>
class threadsafe_stack {
    std::deque<T> m_stack;
    std::mutex m_mutex;
public:
    void push(const T& value) {
        std::lock_guard lock(m_mutex);
        m_stack.push(value);
    }
    void pop() {
        std::lock_guard lock(m_mutex);
        m_stack.pop();
    }
    
    T& top() {
        std::lock_guard lock(m_mutex);
        return m_stack.top();
    }
    bool empty() {
        std::lock_guard lock(m_mutex);
        return m_stack.empty();
    }
    std::size_t size() {
        std::lock_guard lock(m_mutex);
        return m_stack.size();
    }
}; 
```

We did wrap functionalities with synchronization mechanism to achieve thread safety, but it limits true parallel access to the data structure: even though many threads can try to access container, only one can actually do any operation at once. Yet still, there is a race condition in this implementation. 

Consider callable object that first check is stack not empty, then take copy from stack top and remove top element from stack. In this scenario two threads checking `{cpp}empty()` for stack with 1 element, both receive `false` and enter the scope. Then first thread remove top element and at the time second element "granted" to take top element - stack already empty and both `{cpp}top` and `{cpp}pop()` functions call no longer safe. Even if we have more than 1 element in stack, both threads can take same `{cpp}top()` element, but accidentally remove two elements, meaning that result is no longer independent from the order of execution.  
```cpp
if (!stk.empty()) {
	int value = stk.top();
	stk.pop();
}
```

Main source of issue here is interface design itself. To avoid race condition, we can combine together `{cpp}pop()` and `{cpp}top()` functions. We can't simply combine those both functions. To get value from stack, we need to call copy constructor and create temporary object on stack and return copy after removing original element from stack. Before C++17 RVO/copy elision is not guaranteed, meaning that during returning value one more copy constructor can happen, and if that copy constructor throw an exception - we lose original element and copy of element. Actually, even with RVO still there might be chances to get such situation. 
To implement such function, we have several solutions:
1. _Pass in a reference_: we pass into function reference where to store top element
```cpp
void pop(T& value)
{
	std::lock_guard<std::mutex> lock(m);
	if (data.empty()) 
		throw std::runtime_error("stack is empty");
	value = data.top();
	data.pop();
}
```
2. _Return a pointer to popped element_: for this purpose can be useful `std::shared_ptr`:  it avoid memory leaks, the object is destroyed once the last pointer is destroyed, since library is in full control of the memory allocation scheme, and it provide `noexcept` copy constructor 
```cpp
std::shared_ptr<T> pop()
{
	std::lock_guard<std::mutex> lock(m);
	if (data.empty()) 
		throw std::runtime_error("stack is empty");
	std::shared_ptr<T> res {std::make_shared<T>(data.top())};
	data.pop();
	return res;
}
```
3. _Require a no-throw copy or move constructor_, but this not ideal since we also need another solution if type trails `std::is_nothrow_copy_constructible` and `std::is_nothrow_move_constructible` not satisfied. 
4. _Use std::variant_ - similar approach to `std::shared_ptr`, but more lightweight, more understandable interface and can be implement without throwing an exception only if stack element support `noexcept` move constructor.
```cpp
template<typename T>
requires std::is_nothrow_move_constructible_v<T>
std::optional<T> pop() {
    std::lock_guard lock(m_mutex);
    if (m_stack.empty()) 
	    return std::nullopt;
    T element = std::move(m_stack.top());
    m_stack.pop();
    return element;
}
```
We can store instead `{cpp}std::stack<T>` `{cpp}std::stack<std::shared_ptr>>`, add overload for which takes reference (and call `{cpp} value = *(stack.top().get())`). But it's obvious that we add significant overhead for a container wrapper. But still this can be a solution (for a objects which expensive to copy).

## Deadlock
**Deadlock** is a situation where neither thread is able to proceed because they are waiting for each other. 

A typical example of a deadlock is when one thread tries to join a second thread, while the second thread is trying to join the first one. In this case, Thread 2 waits until Thread 1 finishes execution, while Thread 1 waits until Thread 2 finishes execution.

Another example involves two mutexes, `m1` and `m2`. Thread 1 requires locking `m1` first, and then `m2`. Meanwhile, Thread 2 requires locking `m2` first, and then `m1`. In this case, each thread will lock its first mutex but get blocked when attempting to lock the second one. In the following example, it's not immediately obvious that threads can deadlock each other by locking mutexes "in cross" (in different orders).
```cpp
class BankAccount {
    long m_balance;
    std::mutex m;
public:
	BankAccount(long balance) : m_balance{balance} {}
    void withdraw(long amount) {
        std::lock_guard lg(m);
        m_balance -= amount;
    }

    void deposit(long amount) {
        std::lock_guard lg(m);
        m_balance += amount;
    }

    friend void transfer(BankAccount& from, BankAccount& to, long amount);
};

void transfer(BankAccount& from, BankAccount& to, long amount) {
    // Potential Deadlock here if transfer(A, B) and transfer(B, A) 
    // are called simultaneously by different threads.
    std::lock_guard lg_1(from.m);
    std::lock_guard lg_2(to.m);

    from.m_balance -= amount;
    to.m_balance += amount;
}

void main() {
    BankAccount james {2000};
    BankAccount mathew {2000};

    std::thread t1([&]{transfer(mathew, james, 1000);});
    std::thread t2([&]{transfer(james, mathew, 500);});

    t1.join();
    t2.join();
}
```

This deadlock can be solved by locking both mutexes only if both are not locked. One implementation is to use C++17 `{cpp}std::scoped_lock sl(from.m, to.m)` or use `std::unique_lock`.

## std::unique_lock
`std::unique_lock` is a general-purpose mutex ownership wrapper allowing deferred locking, time-constrained attempts at locking, recursive locking, transferring ownership, and use with condition variables. `std::unique_lock` has disabled copy semantics, but has move semantics.

`std::unique_lock`, in addition to the reference to the `std::mutex` it's given, also contains a boolean flag `owns`, which is used to implement different locking strategies. It adds small overhead compared to `std::lock_guard`, but provides deadlock-free mechanisms and _additional exceptions_.

In the `std::unique_lock` constructor, it's also possible to specify tags with a locking strategy:
- _no strategy provided_ - Will act similarly to `std::lock_guard` and try to lock the mutex. Compared to `std::lock_guard`, it can throw an exception with the error code `std::errc::resource_deadlock_would_occur`.
- `std::defer_lock` - Constructs the lock without acquiring the mutex. The mutex remains unlocked, and we must manually lock it either using member functions `{cpp}void lock()`/`{cpp}bool try_lock()` or non-member functions `{cpp}void std::lock(Lockable1& lock1, Lockable2& lock2, LockableN&... lockn)`/`{cpp}int std::try_lock(Lockable1& lock1, Lockable2& lock2, LockableN&... lockn)`.
- `std::try_to_lock` - Attempts to lock the mutex without blocking. If the mutex is already locked by another thread, the constructor returns immediately without waiting. We can check if it succeeded using member function `{cpp}bool owns_lock()`.
- `std::adopt_lock` - Assumes the calling thread already owns the mutex. The lock object takes ownership of an already-locked mutex without attempting to lock it again.

For example, when transferring from one account to another, we can use `std::defer_lock` and try to lock both mutexes simultaneously: if at least one mutex is already locked, we will wait until both mutexes are unlocked again (using `std::lock` algorithm).
```cpp
void transfer(BankAccount& from, BankAccount& to, long amount) {
    std::unique_lock ul_1(from.m, std::defer_lock);
    std::unique_lock ul_2(to.m, std::defer_lock);

    // Locks both mutexes without deadlock
    std::lock(ul_1, ul_2); 
    
    from.m_balance -= amount;
    to.m_balance += amount;
}
```

As was mentioned, `std::unique_lock` supports move semantics, which can be used to transfer ownership over a mutex. In the next example, both function `{cpp}foo()` and `{cpp}bar()` will be executed under the same lock.
```cpp
void foo () { std::cout << "foo() \n"; }
void bar() { std::cout << "bar()\n"; }
std::mutex m;

std::unique_lock<std::mutex> getLock() {
    std::unique_lock<std::mutex> lk(m);
    
    foo();

    return lk;
}

void run() {
    std::unique_lock<std::mutex> lk(getLock()); // construct using move constructor
    bar();
}


int main() {
    std::jthread t1{run};
}
```