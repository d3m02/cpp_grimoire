Algorithms and data that uses synchronization mechanisms (via mutexes, conditional variables and futures) are called _blocking_ data structure and algorithms. Thus, _non-blocking_ algorithms and data structures are such one that doesn't use blocking library.

With lock-free data structures some threads makes progress with every step and with wait-free data structures every thread can make progress regardless of what other threads are doing.

## Stack
> This is continue of [[02. Thread safe access to shared data and locking mechanisms#Thread safe stack implementation.|Thread safe stack implementation]]. Also, author of course probably used as reference 7.2.1 Writing a thread-safe stack without locks from C++ Concurrency in Action 

Previously during observing [[04. Lock based thread safe data structures and algorithm implementation#Thread safe queue implementation|Thread safe queue implementation]] we address issue with using mutex synchronization - it's restrict parallel access to queue data structure and this issues is inherited from used underlying `std::queue` implementation. To achieve better multi-thread implementation we create queue almost from scratch, with some adaptation required to avoid race condition in `push()` and `pop()` functions. 

For stack implementation we can  use `std::atomic` to solve race condition in `{cpp}push()` and `{cpp}pop()` functions call.

In `{cpp}push()` using `{cpp}head.compare_exchange_weak(new_node->next, new_node)` we firstly compare not updated `head` with updated `new_node->next`  which expected to be equal. If comparison succeeded  - `head` will be updated with `new_node`, but if it's failed - another thread probably updated `head` value and in this case `head` value will be loaded to `new_node->next`. Since we use `exchange_weak` which can return `false` if store operation not executed - we need to make attempts until either `head` or `new-node->next` doesn't changed. 

Similar approach can be used in `{cpp}pop()` function - we take `old_head` node from `head` and `{cpp}head.compare_exchange_weak(old_head, old_head->next)` if current `head` and `old_head` equal - exchange `head` with `old_head->next`, if not equal (another thread already changed value) - and we update `old_head` with current (new) `head`. 
In `{cpp}pop()` function we also should consider that if stack is empty, `old_head` can be null pointer.
```cpp title:"Initial fish-bone implementation"
template<typename T>
class lock_free_stack {
    struct node {
        std::shared_ptr<T> data;
        node* next {};
        explicit node(const T& _data) : data(std::make_shared<T>(_data)) {}
    };

    std::atomic<node*> head {nullptr};
public:
    void push(const T& _data) {
        node* new_node = new node(_data);
        new_node->next = head.load();
        while (!head.compare_exchange_weak(new_node->next, new_node));
    }

    std::shared_ptr<T> pop() {
        node* old_head = head.load();
        while (old_head && !head.compare_exchange_weak(old_head, old_head->next));
        return old_head ? old_head->data : std::shared_ptr<T>();
    }
};
```
Problem is that if two threads using `{cpp}pop()` - we have risk of memory leak, since instead one node - we actually "poped" almost entire branch from queue, thus need to remove not one node, but whole branch. If delete node inside pop function - another "sleepy" thread can hold in it's `old_head` node that potentially deleted in another thread.

### Threads counting memory reclamation
One of solution - is modifying to "Threads Counting Memory Reclamation". Idea is that we tracking amount of threads in `{cpp}pop()` function, based on the amount create separate "branch" on nodes that need to me removed and removed that branch when amount of threads in `{cpp}pop()` equal to 1 thread. But even if current threads count if equal to 1 - actually another thread might already enter `{cpp}pop()` function (so called "[ABA problem](https://en.wikipedia.org/wiki/ABA_problem)")

```cpp
template<typename T>
class lock_free_stack {
    struct node {
        std::shared_ptr<T> data;
        node* next {};
        explicit node(const T& _data) : data(std::make_shared<T>(_data)) {}
    };

    static void delete_nodes(node* nodes)
    {
        while (nodes)
        {
            node* next = nodes->next;
            delete nodes;
            nodes = next;
        }
    }

    void chain_pending_nodes(node* nodes)
    {
        node* last = nodes;
        while (node* const next = last->next)
            last=next;
        chain_pending_nodes(nodes, last);
    }

    void chain_pending_nodes(node* first, node* last)
    {
        last->next = to_be_deleted;
        while (!to_be_deleted.compare_exchange_weak(last->next, first));
    }

    void chain_pending_node(node* n)
    {
        chain_pending_nodes(n, n);
    }

    void try_reclaim(node* old_head) {
        if (threads_in_pop == 1) {
            // delete node pointed by old_head
            node* nodes_to_delete = to_be_deleted.exchange(nullptr);

            if (!--threads_in_pop) {
                // if it's 0 - no one entered pop function, and we still last popped thread
                delete_nodes(nodes_to_delete);
            }
            else if (nodes_to_delete) {
                chain_pending_nodes(nodes_to_delete);
            }
            delete old_head;
        }
        else {
            // add new node to branch of to_be_deleted nodes.
            chain_pending_node(old_head);
            --threads_in_pop;
        }
    }
    std::atomic<node*> head {nullptr};
    std::atomic<int> threads_in_pop{};
    std::atomic<node*> to_be_deleted {nullptr};
public:
    std::shared_ptr<T> pop() {
        ++threads_in_pop;

        node* old_head = head.load();
        while (old_head && !head.compare_exchange_weak(old_head, old_head->next));
        std::shared_ptr<T> res;
        if (old_head)
            res.swap(old_head->data);

        try_reclaim(old_head);
        return res;
    }
};
```
This approach still have issues. Garbage cleaning happening when threads_in_pop equal 1 (or rather say 0?). Under heavy load (even with 2 threads) this garbage list can grow, slowing down thread which going to clear list.  Also, each thread should modify `threads_in_pop` twice (increment and decrement) on same atomic variable. 

### Hazard pointers
Another solution - _Hazard pointers_ - list of pair `threadId + pointer address` that currently used in pop function by  threads, preventing from deleting that pointer. When a thread is going to access a node - it's firstly create in hazard list entry. When any thread want to delete node - it has to first check the hazard pointer list first and not delete node if it's found another `threadId` with same pointer to the node, instead it will and add node to delete-list.   
> Both in course and in book examples incomplete. I ask Gemini 3.0 to provide example. At the end - it's a learning example and probably not "product" code

```cpp
constexpr size_t MAX_HAZARD_POINTERS = 100;

struct hazard_pointer {
    std::atomic<std::thread::id> id;
    std::atomic<void*> pointer;
};

hazard_pointer g_hazard_pointers[MAX_HAZARD_POINTERS];

class hp_owner {
    hazard_pointer* hp = nullptr;
public:
    hp_owner() {
        for (auto& g_hazard_pointer : g_hazard_pointers) {
            std::thread::id old_id;
            if (g_hazard_pointer.id.compare_exchange_strong(old_id, std::this_thread::get_id())) {
                hp = &g_hazard_pointer;
                return;
            }
        }
        throw std::runtime_error("No hazard pointers available");
    }

    ~hp_owner() {
        hp->pointer.store(nullptr);
        hp->id.store(std::thread::id());
    }

    [[nodiscard]] std::atomic<void*>& get_ptr() const { return hp->pointer; }

};

template<typename T>
class lock_free_stack {
    struct node {
        std::shared_ptr<T> data;
        node* next = nullptr;
        explicit node(const T& _data) : data(std::make_shared<T>(_data)) {}
    };

    std::atomic<node*> head {nullptr};

public:
    void push(const T& _data) {
        node* new_node = new node(_data);
        new_node->next = head.load();
        while (!head.compare_exchange_weak(new_node->next, new_node));
    }

    std::shared_ptr<T> pop() {
        // Getting for each thread own hazard pointer
        thread_local hp_owner hazard_handler;
        std::atomic<void*>& hp = hazard_handler.get_ptr();

        node* old_head = head.load(std::memory_order_relaxed);

        do {
            node* temp;
            do {
                temp = old_head;
                // Adding currently used node into hazard list
                hp.store(temp);
                // Check that head not changed from another thread
                old_head = head.load(std::memory_order_acquire);
            } while (old_head != temp);

        } while (old_head && !head.compare_exchange_strong(old_head, old_head->next));

        // Releasing protect
        hp.store(nullptr);

        std::shared_ptr<T> res;
        if (old_head) {
            res.swap(old_head->data);

            // Attempt to remove node
            if (check_hazards(old_head)) {
                // node added to hazard list by other thread
                reclaim_later(old_head);
            } else {
                delete old_head;
            }

            // garbage cleaning
            delete_nodes_with_no_hazards();
        }
        return res;
    }

private:
    std::atomic<node*> nodes_to_reclaim {nullptr};

    static bool check_hazards(node* p) {
        for (auto& g_hazard_pointer : g_hazard_pointers) {
            if (g_hazard_pointer.pointer.load() == p)
                return true;
        }
        return false;
    }

    void reclaim_later(node* n) {
        n->next = nodes_to_reclaim.load();
        while (!nodes_to_reclaim.compare_exchange_weak(n->next, n));
    }

    void delete_nodes_with_no_hazards() {
        node* current = nodes_to_reclaim.exchange(nullptr);

        while (current) {
            node* next = current->next;
            if (check_hazards(current)) {
                reclaim_later(current);
            } else {
                delete current;
            }
            current = next;
        }
    }
};
```

### Reference counting memory reclamation
For each node we count two counts: external count and internal count. External count is increased every time the pointer is read. When reader is finished with the node, it decreases the internal counter. The sum of these values is the total number of reference to the particular node. 
```cpp
template<typename T>
class lock_free_stack {
    struct node;
    struct node_wrapper {
        int external_count{};
        node* ptr{};
    };
    struct node {
        explicit node(const T& _data) : data(std::make_shared<T>(_data)) {}

        std::shared_ptr<T> data;
        std::atomic<int> internal_count {};
        node_wrapper next{};
    };

    std::atomic<node_wrapper> head {};

    void increment_head_ext_ref(node_wrapper& old_counter) {
        node_wrapper new_counter;
        do {
            new_counter = old_counter;
            ++new_counter.external_count;
        } while (!head.compare_exchange_strong(old_counter, new_counter,
                                               std::memory_order_acquire, std::memory_order_relaxed));
        old_counter.external_count = new_counter.external_count;
    }

public:
    void push(const T& _data) {
        node_wrapper  new_node;
        new_node.ptr = new node(_data);
        new_node.external_count = 1;
        new_node.ptr->next = head.load(std::memory_order_relaxed);
        while (!head.compare_exchange_weak(new_node.ptr->next, new_node,
                                           std::memory_order_release,std::memory_order_relaxed));
    }

    std::shared_ptr<T> pop() {
        node_wrapper old_head = head.load(std::memory_order_relaxed);
        while (true) {
            // Increment external reference counter for head, since head currently used for reading
            increment_head_ext_ref(old_head);
            node* const ptr = old_head.ptr;
            if (!ptr)
                return std::shared_ptr<T>();

            if (head.compare_exchange_strong(old_head, ptr->next, std::memory_order_relaxed)) {
                // We "own" head node
                std::shared_ptr<T> res;
                res.swap(ptr->data);

                // why -2: we already removed node from stack + current thread will leave scope and no longer using node.
                const int current_external_count = old_head.external_count - 2;
                // If previously compare_exchange failed, we subtracted from internal counter "as credit"
                // Old + Diff = 0; so comparison will be Old = -Diff
                if (ptr->internal_count.fetch_add(current_external_count, std::memory_order_release) == -current_external_count)
                    delete ptr;
                return res;
            }

            // Some other thread modified head (since compare_exchange failed to make write operation in any direction)
            // Decrement internal counter (since we no longer "holding" node but previously incremented reference),
            // instead we take a "credit" in internal counter.
            // If this last thread to hold a reference (because another thread removed it from the stack),
            // the internal reference count will be 1, subtracting 1 will set the count to 0.
            // In this case, node can be deleted
            if (ptr->internal_count.fetch_add(-1, std::memory_order_relaxed) == 1) {
                // connect release sequence and synchronize before deleting
                ptr->internal_count.load(std::memory_order_acquire);
                delete ptr;
            }
        }
    }
};
```

### C++20 atomic shared pointer 
> It's not from course, suggested by Gemini 3.0

Starting from C++20 it's possible to use `std::shared_ptr` with `std::atomic`. Shared pointers already have reference counting, together with atomic operations - this reference counting become thread safe, as result whole implementation quite simple to understand and safe, although it can lose in performance to hazard pointer, but for most scenarios might be suitable enough. 
```cpp
template<typename T>
class lock_free_stack {
    struct Node {
        T data{};
        std::shared_ptr<Node> next{};
        explicit Node(T val) : data(std::move(val)) {}
    };

    // shared_ptr already contain reference counter. With atomic - it's insure thread safety
    std::atomic<std::shared_ptr<Node>> head{};

public:
    void push(T data) {
        auto new_node = std::make_shared<Node>(std::move(data));
        new_node->next = head.load(std::memory_order_relaxed);

        while (!head.compare_exchange_weak(new_node->next, new_node,
                                           std::memory_order_release,
                                           std::memory_order_relaxed)) ;
    }

    std::shared_ptr<T> pop() {
        auto old_head = head.load(std::memory_order_relaxed);

        while (old_head && !head.compare_exchange_weak(old_head, old_head->next,
                                                       std::memory_order_acquire,
                                                       std::memory_order_relaxed)) ;

        return old_head ? std::make_shared<T>(old_head->data) : nullptr;
    }
};
```

As external libraries can be considered [boost::lockfree](https://www.boost.org/doc/libs/latest/doc/html/lockfree.html), [libcds](https://github.com/khizmax/libcds), [folly::hazptr](https://github.com/facebook/folly/blob/main/folly/synchronization/Hazptr.h)
In C++26 also expected [std::hazard_pointers](https://cppreference.com/w/cpp/header/hazard_pointer.html) and [std::rcu_domain](https://cppreference.com/w/cpp/header/rcu.html) (none of compiler implemented it yet)
