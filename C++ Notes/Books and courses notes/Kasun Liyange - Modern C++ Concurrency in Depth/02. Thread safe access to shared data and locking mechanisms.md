**Invariants** — statements regarding program state that are always true. This applies to class logic, algorithms, and data structures. For example, in the doubly linked list data structure, if we follow a `next` pointer from node A to node B, the `prev` pointer in B should point to node A.

The most common problem in multithreaded applications is broken invariants during updates. One particular example is deleting a node from a doubly linked list. In the doubly linked list data structure, if we follow a `next` pointer from node A to node B, the `prev` pointer in B should point to node A — this is an invariant for a doubly linked list. Deleting one node requires two steps:
1. Change node A's `next` pointer to node C (instead of B).
2. Change node C's `prev` pointer to node A (instead of B).

But let's say that after executing step 1, another thread tries to read the list in reverse order. In this case, node B's `prev` pointer points to node A, but node A's `next` pointer is already pointing to node C. This situation represents a broken invariant. In this scenario, if another thread starts removing another node, the data structure as a whole becomes invalid.

**Race condition** — in concurrency, a race condition is anything where the outcome depends on the relative ordering of the execution of operations on two or more threads. In most cases, the order of execution doesn't affect the result, but for problematic race conditions (specifically _data races_ in C++), we need additional management to receive valid output.

## Mutex 
The `std::mutex` is a synchronization primitive that can be used to protect shared data from being simultaneously accessed by multiple threads. We can simply say that mutex provides mutual exclusive access of shared data for multiple threads. 

Let's take as an example scenario of adding new element to `std::list`. `std::list` is not built as thread-safe data structure. STL containers generally offer basic thread safety (safe for concurrent reads), but they are _not thread-safe for concurrent writes_. Pushing an element to list is not atomic operation and it in general contain 3 steps: creating new node, setting `next` pointer of that node to current head node and changing in head node `prev` pointer to the new node. If two threads start adding new element, only one node will be accessible from old head node, meaning that another node will be lost. Thus, when we already have some mutable operation, we need to prevent another node from starting same operation until first operation not finished. 

`std::mutex` have only three member functions: 
+ `{cpp} void lock()` - locks mutex, if another thread has already locked the mutex, a call to `lock` will block execution until the lock is acquired.
+ `{cpp}void unlock()` - unlocks the mutex. The mutex must be locked by the current thread of execution.
+ `{cpp} bool try_lock()` - tries to lock the mutex and returns immediately `true` if mutex get locked.

When a thread calls `lock()` on an already locked mutex, the operating system puts the thread to sleep (removes it from the CPU scheduling queue). The thread consumes no processor time until the mutex is unlocked and the OS wakes the thread up.

For `std::list` example, inside callable object we firstly lock the mutex. When another thread tries to lock the mutex, it will be blocked until the first thread releases the mutex. After the first thread unlocks the mutex, the execution of the second thread will be resumed by the OS, and now the second thread acquires the lock.
```cpp
std::list<int> list;
std::mutex m;

void addToList(const int x) {
	m.lock();
	list.push_front(x);
	m.unlock();
}

void func() {
	std::jthread t1 {addToList, 4};
	std::jthread t2 {addToList, 11};
}
```

As we can notice from example, unlocking mutex is crucial part. If the first thread does not unlock the mutex (e.g., due to an exception), two critical problems arise:
1. _Starvation:_ Other threads waiting for this mutex will be blocked forever.
2. _Undefined Behavior (Self-Deadlock):_ If the thread that holds the lock attempts to catch the exception and lock the mutex again, it triggers Undefined Behavior (since `std::mutex` is non-recursive), typically resulting in a self-deadlock.

To avoid such situations, we should use an RAII wrapper. The STL provides the class `std::lock_guard(mutex_type& m);` — a mutex wrapper that provides a convenient RAII-style mechanism for owning a mutex for the duration of a scoped block. When a `std::lock_guard` object is created, it attempts to take ownership of the mutex it's given. After leaving the scope, the `std::lock_guard` object is destroyed, unlocking the mutex in the destructor.
Starting from C++17 STL also provides `{cpp}std::scoped_lock(MutexTypes&... m);` - similar to `std::lock_guard` RAII wrapper, but with ability to lock multiple mutexes using a deadlock avoidance algorithm

```cpp
std::list<int> list;
std::mutex m;

void addToList(const int x) {
	std::lock_guard<std::mutex> lg(m);
	list.push_front(x);
}

void func() {
	std::jthread t1 {addToList, 4};
	std::jthread t2 {addToList, 11};
}
```

## Thread safe stack implementation. 
STL provides an implementation of a LIFO (last-in, first-out) data structure - `std::stack`. It's not a container, it's a container adapter, which can be based on top of `std::deque`. As we mentioned, STL containers doesn't provide thread safety for writing operation.

We can solve this issue by creating own `stack` implementation  using `std::stack` as underlying container. Container adapters usually simply call member function of underlying container. We going to protect those calls to underlying container with `std::mutex` and `std::lock_guard` to prevent situations, when two thread trying to simultaneously modify container or one thread adding removing one element while another checking is container not empty. 
```cpp
template<typename T>
class threadsafe_stack {
    std::deque<T> m_stack;
    std::mutex m_mutex;
public:
    void push(const T& value) {
        std::lock_guard lock(m_mutex);
        m_stack.push(value);
    }
    void pop() {
        std::lock_guard lock(m_mutex);
        m_stack.pop();
    }
    
    T& top() {
        std::lock_guard lock(m_mutex);
        return m_stack.top();
    }
    bool empty() {
        std::lock_guard lock(m_mutex);
        return m_stack.empty();
    }
    std::size_t size() {
        std::lock_guard lock(m_mutex);
        return m_stack.size();
    }
}; 
```

We did wrap functionalities with synchronization mechanism to achieve thread safety, but it limits true parallel access to the data structure: even though many threads can try to access container, only one can actually do any operation at once. Yet still, there is a race condition in this implementation. 

Consider callable object that first check is stack not empty, then take copy from stack top and remove top element from stack. In this scenario two threads checking `{cpp}empty()` for stack with 1 element, both receive `false` and enter the scope. Then first thread remove top element and at the time second element "granted" to take top element - stack already empty and both `{cpp}top` and `{cpp}pop()` functions call no longer safe. Even if we have more than 1 element in stack, both threads can take same `{cpp}top()` element, but accidentally remove two elements, meaning that result is no longer independent from the order of execution.  
```cpp
if (!stk.empty()) {
	int value = stk.top();
	stk.pop();
}
```

Main source of issue here is interface design itself. To avoid race condition, we can combine together `{cpp}pop()` and `{cpp}top()` functions. We can't simply combine those both functions. To get value from stack, we need to call copy constructor and create temporary object on stack and return copy after removing original element from stack. Before C++17 RVO/copy elision is not guaranteed, meaning that during returning value one more copy constructor can happen, and if that copy constructor throw an exception - we lose original element and copy of element. Actually, even with RVO still there might be chances to get such situation. 
To implement such function, we have several solutions:
1. _Pass in a reference_: we pass into function reference where to store top element
```cpp
void pop(T& value)
{
	std::lock_guard<std::mutex> lock(m);
	if (data.empty()) 
		throw std::runtime_error("stack is empty");
	value = data.top();
	data.pop();
}
```
2. _Return a pointer to popped element_: for this purpose can be useful `std::shared_ptr`:  it avoid memory leaks, the object is destroyed once the last pointer is destroyed, since library is in full control of the memory allocation scheme, and it provide `noexcept` copy constructor 
```cpp
std::shared_ptr<T> pop()
{
	std::lock_guard<std::mutex> lock(m);
	if (data.empty()) 
		throw std::runtime_error("stack is empty");
	std::shared_ptr<T> res {std::make_shared<T>(data.top())};
	data.pop();
	return res;
}
```
3. _Require a no-throw copy or move constructor_, but this not ideal since we also need another solution if type trails `std::is_nothrow_copy_constructible` and `std::is_nothrow_move_constructible` not satisfied. 
4. _Use std::variant_ - similar approach to `std::shared_ptr`, but more lightweight, more understandable interface and can be implement without throwing an exception 
```cpp
std::optional<T> pop() {
    std::lock_guard lock(m_mutex);
    if (m_stack.empty()) 
	    return std::nullopt;
    T element = std::move(m_stack.top());
    m_stack.pop();
    return element;
}
```
We can store instead `{cpp}std::stack<T>` `{cpp}std::stack<std::shared_ptr>>`, add overload for which takes reference (and call `{cpp} value = *(stack.top().get())`). But it's obvious that we add significant overhead for a container wrapper. But still this can be a solution (for a objects which expensive to copy).